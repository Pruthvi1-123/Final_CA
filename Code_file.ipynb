{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a048da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preview dataset\n",
    "df = pd.read_csv(\"customer_support_tickets.csv\", encoding='utf-8')\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0539106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename and validate columns\n",
    "required_cols_mapping = {\n",
    "    \"Ticket Description\": \"Ticket Description\",\n",
    "    \"Ticket Type\": \"Ticket Type\",\n",
    "    \"Ticket Priority\": \"Ticket Priority\",\n",
    "    \"gender\": \"Customer Gender\"\n",
    "}\n",
    "\n",
    "# Check if required columns exist\n",
    "missing = [v for v in required_cols_mapping.values() if v not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "# Standardize column names\n",
    "df = df.rename(columns={v: k for k, v in required_cols_mapping.items()})\n",
    "print(\"‚úÖ Renamed columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7605fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# Custom text cleaning function\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # remove URLs\n",
    "    text = re.sub(r\"\\s+\", ' ', text)  # remove extra spaces\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # remove punctuation\n",
    "    return text.strip()\n",
    "\n",
    "# Apply cleaning to ticket descriptions\n",
    "df[\"Ticket Description\"] = df[\"Ticket Description\"].apply(clean_text)\n",
    "\n",
    "# Drop rows with empty values in key columns\n",
    "df = df.dropna(subset=[\"Ticket Description\", \"Ticket Type\", \"Ticket Priority\"])\n",
    "print(\"‚úÖ Cleaned ticket descriptions and dropped missing rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8179d2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Display structure\n",
    "print(\"\\nüìä Dataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nüìà Statistical Summary:\")\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# Check missing values\n",
    "print(\"\\nüßº Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Value counts for categorical features\n",
    "print(\"\\nüìå Ticket Type Distribution:\")\n",
    "print(df[\"Ticket Type\"].value_counts())\n",
    "\n",
    "print(\"\\nüìå Ticket Priority Distribution:\")\n",
    "print(df[\"Ticket Priority\"].value_counts())\n",
    "\n",
    "# Plot ticket type distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(data=df, x=\"Ticket Type\", palette=\"viridis\")\n",
    "plt.title(\"Distribution of Ticket Types\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot ticket priority distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df, x=\"Ticket Priority\", palette=\"plasma\")\n",
    "plt.title(\"Distribution of Ticket Priorities\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ticket length analysis\n",
    "df[\"Text Length\"] = df[\"Ticket Description\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(df[\"Text Length\"], bins=20, kde=True, color=\"teal\")\n",
    "plt.title(\"Distribution of Ticket Description Length\")\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f91ecd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# BERT embeddings\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def bert_embed(texts):\n",
    "    inputs = tokenizer(texts.tolist(), return_tensors=\"tf\", padding=True, truncation=True)\n",
    "    outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "X = bert_embed(df[\"cleaned_text\"])\n",
    "\n",
    "# Label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_type = LabelEncoder()\n",
    "le_priority = LabelEncoder()\n",
    "\n",
    "y_type = le_type.fit_transform(df[\"Ticket Type\"])\n",
    "y_priority = le_priority.fit_transform(df[\"Ticket Priority\"])\n",
    "y = np.vstack((y_type, y_priority)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe8332",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Split original\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separate labels\n",
    "y_type_train = y_train[:, 0]\n",
    "y_priority_train = y_train[:, 1]\n",
    "\n",
    "# Apply SMOTE only on 'type'\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_type_res = smote.fit_resample(X_train, y_type_train)\n",
    "\n",
    "# Fix: Use the indices of X_train in the resampled data\n",
    "# We'll use the nearest neighbors to rebuild matching priority labels\n",
    "# This approximation works fine for multi-output\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nn = NearestNeighbors(n_neighbors=1).fit(X_train)\n",
    "_, indices = nn.kneighbors(X_train_res)\n",
    "\n",
    "priority_res = y_priority_train[indices.flatten()]\n",
    "\n",
    "# Combine\n",
    "y_train_res = np.vstack((y_type_res, priority_res)).T\n",
    "\n",
    "# Train model\n",
    "model = MultiOutputClassifier(LogisticRegression(max_iter=500))\n",
    "model.fit(X_train_res, y_train_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ea0cd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d402a2ed",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Split original\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separate labels\n",
    "y_type_train = y_train[:, 0]\n",
    "y_priority_train = y_train[:, 1]\n",
    "\n",
    "# Apply SMOTE only on 'type'\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_type_res = smote.fit_resample(X_train, y_type_train)\n",
    "\n",
    "# Fix: Use the indices of X_train in the resampled data\n",
    "# We'll use the nearest neighbors to rebuild matching priority labels\n",
    "# This approximation works fine for multi-output\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nn = NearestNeighbors(n_neighbors=1).fit(X_train)\n",
    "_, indices = nn.kneighbors(X_train_res)\n",
    "\n",
    "priority_res = y_priority_train[indices.flatten()]\n",
    "\n",
    "# Combine\n",
    "y_train_res = np.vstack((y_type_res, priority_res)).T\n",
    "\n",
    "# Train model\n",
    "model = MultiOutputClassifier(LogisticRegression(max_iter=500))\n",
    "model.fit(X_train_res, y_train_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ce8e2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, target_names):\n",
    "    metrics = {}\n",
    "    for i, name in enumerate(target_names):\n",
    "        p, r, f, _ = precision_recall_fscore_support(y_true[:, i], y_pred[:, i], average='weighted', zero_division=0)\n",
    "        metrics[name] = {'precision': round(p, 3), 'recall': round(r, 3), 'f1': round(f, 3)}\n",
    "    return metrics\n",
    "\n",
    "metrics = evaluate_model(y_test, y_pred, [\"type\", \"priority\"])\n",
    "print(metrics)\n",
    "\n",
    "# Confusion Matrices\n",
    "ConfusionMatrixDisplay.from_predictions(y_test[:,0], y_pred[:,0])  # Type\n",
    "ConfusionMatrixDisplay.from_predictions(y_test[:,1], y_pred[:,1])  # Priority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e5130f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Quick Model Evaluation (Fix for Type and Priority separately)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    # Ticket Type evaluation\n",
    "    print(\"üîπ Classification Report for Ticket Type:\")\n",
    "    print(classification_report(y_test[:, 0], y_pred[:, 0]))  # 0: Ticket Type\n",
    "\n",
    "    cm_type = confusion_matrix(y_test[:, 0], y_pred[:, 0])\n",
    "    disp_type = ConfusionMatrixDisplay(confusion_matrix=cm_type)\n",
    "    disp_type.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix - Ticket Type\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Ticket Priority evaluation\n",
    "    print(\"\\nüî∏ Classification Report for Ticket Priority:\")\n",
    "    print(classification_report(y_test[:, 1], y_pred[:, 1]))  # 1: Priority\n",
    "\n",
    "    cm_priority = confusion_matrix(y_test[:, 1], y_pred[:, 1])\n",
    "    disp_priority = ConfusionMatrixDisplay(confusion_matrix=cm_priority)\n",
    "    disp_priority.plot(cmap=plt.cm.Oranges)\n",
    "    plt.title(\"Confusion Matrix - Ticket Priority\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Evaluation Error: {str(e)}\")\n",
    "    print(\"Make sure y_test and y_pred are NumPy arrays with two columns (type and priority).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d59c8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Use smaller test sample\n",
    "X_sample = X_test[:5]\n",
    "\n",
    "# Predict class probabilities\n",
    "def predict_type(X):\n",
    "    return model.estimators_[0].predict_proba(X)\n",
    "\n",
    "# Get class index with highest predicted probability\n",
    "predicted_class_type = np.argmax(predict_type(X_sample), axis=1)[0]\n",
    "\n",
    "# Explain only that class\n",
    "explainer_type = shap.Explainer(predict_type, X_sample)\n",
    "shap_values_type = explainer_type(X_sample, max_evals=2000)\n",
    "\n",
    "# Use only the SHAP values for predicted class\n",
    "shap.plots.beeswarm(shap_values_type[:, :, predicted_class_type], show=False)\n",
    "plt.title(\"SHAP - Ticket Type (Top Class)\")\n",
    "plt.savefig(\"shap_type_beeswarm.png\", bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a34700",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# SHAP wrapper for priority prediction\n",
    "def predict_priority(X):\n",
    "    return model.estimators_[1].predict_proba(X)\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer_priority = shap.Explainer(predict_priority, X_sample)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values_priority = explainer_priority(X_sample, max_evals=2000)\n",
    "\n",
    "# Plot and save\n",
    "shap.plots.beeswarm(shap_values_priority[:, :, y_test[0][1]], show=False)\n",
    "plt.title(\"SHAP - Ticket Priority\")\n",
    "plt.savefig(\"shap_priority_beeswarm.png\", bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbab7c6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# LIME Explanation\n",
    "explainer = LimeTextExplainer(class_names=le_type.classes_)\n",
    "\n",
    "def explain_pred(text):\n",
    "    exp = explainer.explain_instance(\n",
    "        text_instance=text,\n",
    "        classifier_fn=lambda x: model.predict(bert_embed(pd.Series(x))),\n",
    "        num_features=10\n",
    "    )\n",
    "    return exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66da253",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Choose any ticket message to test LIME\n",
    "sample_text = df[\"cleaned_text\"].iloc[25]  # You can change the index to test other examples\n",
    "explain_pred(sample_text)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
