{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd8a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Basic machine learning imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# For handling imbalanced data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# For text processing\n",
    "import re\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faec655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_data(filepath=\"customer_support_tickets.csv\"):\n",
    "    \"\"\"\n",
    "    Load the support ticket data and perform initial exploration\n",
    "    This helps us understand what we're working with\n",
    "    \"\"\"\n",
    "    print(\"\\nSTEP 1: Loading and exploring the data\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    try:\n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(filepath, encoding='utf-8')\n",
    "        print(f\"Successfully loaded dataset with {len(df):,} tickets\")\n",
    "        \n",
    "        # Show basic information about the dataset\n",
    "        print(f\"Dataset shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "        print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "        # Display column names\n",
    "        print(f\"\\nColumns in dataset: {list(df.columns)}\")\n",
    "        \n",
    "        # Show first few rows to understand the data structure\n",
    "        print(f\"\\nFirst 3 rows of data:\")\n",
    "        print(df.head(3))\n",
    "        \n",
    "        # Check for missing values\n",
    "        print(f\"\\nMissing values per column:\")\n",
    "        missing_data = df.isnull().sum()\n",
    "        for col, missing in missing_data.items():\n",
    "            if missing > 0:\n",
    "                print(f\"  {col}: {missing} missing ({missing/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        if missing_data.sum() == 0:\n",
    "            print(\"  No missing values found - excellent data quality\")\n",
    "        \n",
    "        # Check for duplicates\n",
    "        duplicates = df.duplicated().sum()\n",
    "        print(f\"\\nDuplicate records: {duplicates} ({duplicates/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find file '{filepath}'\")\n",
    "        print(\"Please make sure the CSV file is in the same directory as this notebook\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Load the data\n",
    "df = load_and_explore_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a6163c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
